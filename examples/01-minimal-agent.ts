/**
 * 01-minimal-agent.ts
 *
 * æœ€ç®€ Agent - åªæœ‰ LLMï¼Œæ²¡æœ‰ä»»ä½•é¢å¤–èƒ½åŠ›
 *
 * 2025 å¹´èµ·ç‚¹ï¼š
 * - API å·²å†…ç½® Agentic Loopï¼ˆä½ ä¸ç”¨å†™å¾ªç¯ï¼‰
 * - LangChain çš„ createAgent å°è£…äº†è¿™ä¸ªèƒ½åŠ›
 * - ä½ åªéœ€è¦å®šä¹‰ model å’Œ tools
 *
 * åç»­ç¤ºä¾‹ä¼šé€æ­¥æ·»åŠ ï¼š
 * - 02: + Tools (è‡ªå®šä¹‰å·¥å…·)
 * - 03: + Memory (æŒä¹…èº«ä»½)
 * - 04: + Filesystem (æ–‡ä»¶è¯»å†™)
 * - 05: + Skills (å¯å¤ç”¨å·¥ä½œæµ)
 * - 06: + SubAgents (ä¸“ä¸šåˆ†å·¥)
 *
 * è¿è¡Œ: npx tsx examples/01-minimal-agent.ts
 */

import "dotenv/config";
import { createAgent } from "langchain";
import { ChatOpenAI } from "@langchain/openai";

// ============================================================
// 1. åˆ›å»º LLM
// ============================================================

function createLLM() {
  return new ChatOpenAI({
    model: process.env.DEFAULT_LLM_MODEL || "qwen-plus",
    apiKey: process.env.DASHSCOPE_API_KEY,
    configuration: {
      baseURL:
        process.env.DASHSCOPE_BASE_URL ||
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
    },
  });
}

// ============================================================
// 2. åˆ›å»ºæœ€ç®€ Agent
// ============================================================

/**
 * createAgent æ˜¯ LangChain æä¾›çš„ Agent å·¥å‚
 *
 * å®ƒå†…ç½®äº†ï¼š
 * - Agentic Loopï¼ˆä½ ä¸ç”¨å†™ while å¾ªç¯ï¼‰
 * - å·¥å…·æ‰§è¡Œå’Œé”™è¯¯å¤„ç†
 * - æ¶ˆæ¯å†å²ç®¡ç†
 *
 * æœ€ç®€å½¢å¼ï¼šåªæœ‰ modelï¼Œæ²¡æœ‰ tools
 * è¿™å°±æ˜¯ä¸€ä¸ªçº¯å¯¹è¯ Agent
 */
const agent = createAgent({
  model: createLLM(),
  tools: [], // æ²¡æœ‰å·¥å…· - çº¯ LLM å¯¹è¯
});

// ============================================================
// 3. è¿è¡Œ
// ============================================================

async function main() {
  console.log("\nğŸš€ 01-minimal-agent: æœ€ç®€ Agent\n");
  console.log("â•".repeat(60));
  console.log("2025 å¹´èµ·ç‚¹ï¼šAPI å·²å†…ç½® Agentic Loop");
  console.log("");
  console.log("  import { createAgent } from 'langchain';");
  console.log("");
  console.log("  createAgent({");
  console.log("    model: createLLM(),");
  console.log("    tools: [],  // æ²¡æœ‰å·¥å…·");
  console.log("  })");
  console.log("");
  console.log("å®ƒèƒ½åšä»€ä¹ˆï¼Ÿåªèƒ½å¯¹è¯ï¼Œä¸èƒ½ï¼š");
  console.log("  âŒ æœç´¢ç½‘é¡µ (éœ€è¦ Tools)");
  console.log("  âŒ è¯»å†™æ–‡ä»¶ (éœ€è¦ Filesystem)");
  console.log("  âŒ ä¿æŒèº«ä»½ (éœ€è¦ Memory)");
  console.log("  âŒ å¤ç”¨å·¥ä½œæµ (éœ€è¦ Skills)");
  console.log("  âŒ å§”æ‰˜å­ä»»åŠ¡ (éœ€è¦ SubAgents)");
  console.log("â•".repeat(60));

  const task = "å¸®æˆ‘åˆ—å‡ºå®Œæˆä¸€ç¯‡åšå®¢æ–‡ç« éœ€è¦çš„æ­¥éª¤";

  console.log(`\nğŸ“ ä»»åŠ¡: ${task}\n`);
  console.log("â”€".repeat(60));

  const result = await agent.invoke({
    messages: [{ role: "user", content: task }],
  });

  // è·å–æœ€åä¸€æ¡æ¶ˆæ¯
  const lastMessage = result.messages[result.messages.length - 1];
  const content =
    "content" in lastMessage
      ? typeof lastMessage.content === "string"
        ? lastMessage.content
        : JSON.stringify(lastMessage.content)
      : "";

  console.log("\nğŸ“„ Agent å›å¤:");
  console.log("â”€".repeat(60));
  console.log(content);

  console.log("\n" + "â•".repeat(60));
  console.log("è§‚å¯Ÿï¼šAgent åªèƒ½ç»™å‡ºå»ºè®®ï¼Œä¸èƒ½å®é™…æ‰§è¡Œä»»ä½•æ“ä½œ");
  console.log("ä¸‹ä¸€æ­¥ï¼š02-with-tools.ts æ·»åŠ å·¥å…·èƒ½åŠ›");
  console.log("â•".repeat(60));
}

main().catch(console.error);
